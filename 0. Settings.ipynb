{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6b21ab",
   "metadata": {},
   "source": [
    "# 0. Visual Search - Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36772ccb",
   "metadata": {},
   "source": [
    "# Visual Search with Azure Cognitive Search, Sentence Transformers, Azure Computer Vision and bar code/QR code detection\n",
    "\n",
    "## 1. Description\n",
    "The goal of this is **Azure AI asset is to enable search over Text and Images using Azure Cognitive Search**. The technique was inspired by a research article which show how to **convert vectors (embeddings) to text which allows the Cognitive Search service to leverage the inverted index to quickly find the most relevant items**. For this reason, any model that will convert an object to a vector can be leveraged if the number of dimensions in the resulting vector is less than 3,000. It also allows users to leverage existing pretrained or fine-tuned models.<br><br>\n",
    "\n",
    "This technique has shown to be incredibly effective and easy to implement. We are using **Sentence Transformers, which is an OpenAI clip model wrapper**. We need to embed all our existing catalog of images. Then the objects embedding are converted into a set of fake terms and all the results are stored into an Azure Cognitive Search index for handling all the search requests.\n",
    "For example, if an embedding looked like [-0,21, .123, ..., .876], this might be converted to a set of fake terms such as: “A1 B3 … FED0”. This is what is sent as the search query to Azure Cognitive Search.<br><br>\n",
    "\n",
    "We can **enrich the Azure Cognitive Search index by using extracted text from the images using Azure Read API**. We can also detect and extract any information from **bar code and/or QR code** that might be available in the products catalog images. And we can use also **Azure Computer Vision as well to detect the dominant colors of the image, the tags that can describe the image and the caption of each image**. All these information will be ingested into the Azure Cognitive Search index.<br><br>\n",
    "\n",
    "The goal of this asset is to be able to use the inverted index within Azure Cognitive Search to be able to quickly find vectors stored in the search index that are like a vector provided as part of a search query and/or using any AI extracted information (text, dominant colors, …). Unlike techniques like cosine similarity which are slow to process large numbers of items, this leverages an inverted index which enables much more data to be indexed and searched.<br>\n",
    "\n",
    "## 2. Process\n",
    "\n",
    "- We have here a collection of catalog images (466 images).\n",
    "- For each of these images, we will embed them using Sentence Transformers.  Sentence Transformer can be used to map images and texts to the same vector space. As model, we use the OpenAI CLIP Model which was trained on a large set of images and image alt texts.\n",
    "- We can retrieve any text from these images using Azure Read API (if any text is available)\n",
    "- We can retrieve any text information from any bar code or QR code (if any)\n",
    "- All these information will be ingested into an Azure Cognitive Search index\n",
    "- Then if you have a field image, you can embed it and extract any text/barcode information and call the Azure Cognitive Search index to retrieve any similar images using vecText similarity and/or using any query text from the extracted text\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/retkowsky/images/blob/master/process.png?raw=true\">\n",
    "\n",
    "Field images are available in the field images directory (number of images=53)\n",
    "\n",
    "\n",
    "## 3. Azure products documentation\n",
    "- https://azure.microsoft.com/en-us/products/search/ \n",
    "- https://azure.microsoft.com/en-us/products/cognitive-services/computer-vision/#overview \n",
    "- https://learn.microsoft.com/en-us/azure/cognitive-services/Computer-vision/how-to/call-read-api \n",
    "- https://zbar.sourceforge.net/ \n",
    "- https://github.com/liamca/vector-search\n",
    "\n",
    "## 4. Research article\n",
    "https://www.researchgate.net/publication/305910626_Large_Scale_Indexing_and_Searching_Deep_Convolutional_Neural_Network_Features\n",
    "    \n",
    "## 5. Directories\n",
    "- **images**: We have two directories (catalog images, field images)\n",
    "- **model**: Directory to save the clusters of the model\n",
    "- **results**: Directory to save some results\n",
    "- **test**: Directory that contains some testing images\n",
    "\n",
    "## 6. Python notebooks\n",
    "\n",
    "### 0. Settings.ipynb\n",
    "Notebook that contains the link to the images and the importation process of the python required libraries\n",
    "\n",
    "### 1. Catalog images exploration.ipynb\n",
    "This notebook will display some catalog and field images\n",
    "\n",
    "### 2.OpenAI Clip and VecText Clusters.ipynb\n",
    "This notebook will explain what sentence transformers is and will generate the clusters\n",
    "This notebook analyzes a set of existing images to determine a set of \"cluster centers\" that will be used to determine which \"fake words\" are generated for a vector\n",
    "This notebook will take a test set of files (testSamplesToTest) and determine the optimal way to cluster vectors into fake words that will be indexed into Azure Cognitive Search\n",
    "\n",
    "### 3. VecText generation.ipynb\n",
    "This notebook will generate the vectext embedding for all the catalog images\n",
    "\n",
    "### 4. BarCode Information extraction.ipynb\n",
    "This notebook will detect any barcode or QR code from the catalog images and will extract the information\n",
    "\n",
    "### 5. Azure CV for OCR, tags, colors and captions.ipynb\n",
    "This notebook will use Azure Computer Vision or OCR, colors, tags and caption extraction for each of the catalog images.\n",
    "\n",
    "### 6. Azure Cognitive Search Index Generation.ipynb\n",
    "This notebook will show how to ingest all the information into an Azure Cognitive Search index.\n",
    "\n",
    "### 7. Calling Azure Cognitive Search.ipynb\n",
    "We can now test the index using some images similarity visual search or free text queries using azure Cognitive Search.\n",
    "\n",
    "## 7. Python files\n",
    "\n",
    "- **azureCognitiveSearch.py**\n",
    "This python file contains many functions to manage and use Azure Cognitive Search\n",
    "\n",
    "- **myfunctions.py**\n",
    "This python file contains many generic functions used in all the notebooks\n",
    "\n",
    "- **vec2Text.py**\n",
    "This python file contains some functions for the sentence transformers model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c456471",
   "metadata": {},
   "source": [
    "18-Oct-2022 Serge Retkowsky | serge.retkowsky@microsoft.com | https://www.linkedin.com/in/serger/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce617fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import myfunctions as my\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1de27a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e555f21",
   "metadata": {},
   "source": [
    "## 1. azureCognitiveSearch.py\n",
    "> This is a custom .py file with some Azure Cognitive Search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3bc4a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing file: azureCognitiveSearch.py \n",
      "\n",
      "# Azure Cognitive Search python functions\n",
      "# 18-Oct-2022\n",
      "\n",
      "\n",
      "# Multiple imports\n",
      "import os\n",
      "import configparser\n",
      "import requests\n",
      "import json\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "import time\n",
      "import vec2Text\n",
      "\n",
      "import myfunctions as my\n",
      "\n",
      "from azure.core.credentials import AzureKeyCredential\n",
      "from azure.search.documents.indexes import SearchIndexClient\n",
      "from azure.search.documents import SearchClient\n",
      "from azure.search.documents.indexes.models import (\n",
      "    ComplexField,\n",
      "    CorsOptions,\n",
      "    SearchIndex,\n",
      "    ScoringProfile,\n",
      "    SearchFieldDataType,\n",
      "    SimpleField,\n",
      "    SearchableField,\n",
      ")\n",
      "from IPython.display import Image\n",
      "\n",
      "# Azure Cognitive Search connection\n",
      "config_file = 'azureconfig.ini'\n",
      "\n",
      "# Azure Cognitive Search Index name\n",
      "index_name = \"demo-retail\"\n",
      "\n",
      "# Azure Cognitive Search credentials\n",
      "config = configparser.ConfigParser()\n",
      "config.read(config_file)\n",
      "acs_key = config.get('AzureCognitiveSearch', 'key')\n",
      "acs_endpoint = config.get('AzureCognitiveSearch', 'endpoint')\n",
      "servicename = config.get('AzureCognitiveSearch', 'servicename')\n",
      "\n",
      "# Azure Cognitive Search admin and search clients\n",
      "adminClient = SearchIndexClient(endpoint=acs_endpoint,\n",
      "                                index_name=index_name,\n",
      "                                credential=AzureKeyCredential(acs_key))\n",
      "\n",
      "searchClient = SearchClient(endpoint=acs_endpoint,\n",
      "                            index_name=index_name,\n",
      "                            credential=AzureKeyCredential(acs_key))\n",
      "\n",
      "# User functions for Azure Cognitive Search\n",
      "\n",
      "\n",
      "def create_index():\n",
      "    \"\"\"\n",
      "    Creating a new index\n",
      "    \"\"\"\n",
      "    name = index_name\n",
      "    fields = [\n",
      "        SimpleField(name=\"Id\", type=SearchFieldDataType.String, key=True),\n",
      "        SearchableField(name=\"Content\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=True,\n",
      "                        sortable=True,\n",
      "                        analyzer_name=\"en.microsoft\"),\n",
      "        SearchableField(name=\"VecText\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=False,\n",
      "                        sortable=False),\n",
      "        SearchableField(name=\"Ocrtext\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=True,\n",
      "                        sortable=True),\n",
      "        SearchableField(name=\"Barcodetext\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=True,\n",
      "                        sortable=True),\n",
      "        SearchableField(name=\"Colors\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=True,\n",
      "                        sortable=True),\n",
      "        SearchableField(name=\"Tags\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=True,\n",
      "                        sortable=True),\n",
      "        SearchableField(name=\"Caption\",\n",
      "                        type=SearchFieldDataType.String,\n",
      "                        facetable=False,\n",
      "                        filterable=True,\n",
      "                        sortable=True),\n",
      "    ]\n",
      "\n",
      "    cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\n",
      "    index = SearchIndex(name=name, fields=fields, cors_options=cors_options)\n",
      "\n",
      "    try:\n",
      "        print(\"Creating new index\", index_name)\n",
      "        result = adminClient.create_index(index)\n",
      "        print(result.name, \"index has been created\")\n",
      "\n",
      "    except Exception as ex:\n",
      "        print(ex)\n",
      "\n",
      "\n",
      "def delete_index():\n",
      "    \"\"\"\n",
      "    Delete any existing Azure cognitive search index\n",
      "    \"\"\"\n",
      "    try:\n",
      "        print(\"Deleting index\", index_name)\n",
      "        result = adminClient.delete_index(index_name)\n",
      "        print(index_name, 'index has been deleted')\n",
      "\n",
      "    except Exception as ex:\n",
      "        print(ex)\n",
      "\n",
      "\n",
      "def execute_file_search(imagefile, centers, model, topn=10):\n",
      "    \"\"\"\n",
      "    File search\n",
      "    \"\"\"\n",
      "    return searchClient.search(search_text=vec_image_to_text(\n",
      "        imagefile, centers, model),\n",
      "                               include_total_count=True,\n",
      "                               select='Content',\n",
      "                               top=topn)\n",
      "\n",
      "\n",
      "def execute_query_search(textquery, centers, model, topn):\n",
      "    \"\"\"\n",
      "    Query search\n",
      "    \"\"\"\n",
      "    return searchClient.search(search_text=vec_query_to_text(\n",
      "        textquery, centers, model),\n",
      "                               include_total_count=True,\n",
      "                               select='Content',\n",
      "                               top=topn)\n",
      "\n",
      "\n",
      "def index_status(index_name):\n",
      "    \"\"\"\n",
      "    Azure cognitive search Index status\n",
      "    \"\"\"\n",
      "    print(\"Azure Cognitive Search Index:\", index_name, \"\\n\")\n",
      "    headers = {'Content-Type': 'application/json', 'api-key': acs_key}\n",
      "    params = {'api-version': '2020-06-30'}\n",
      "    indexstatus = requests.get(acs_endpoint + \"/indexes/\" + index_name,\n",
      "                               headers=headers,\n",
      "                               params=params)\n",
      "    print(json.dumps((indexstatus.json()), indent=4))\n",
      "\n",
      "\n",
      "def global_search(imagefile, centers, model, topn=5):\n",
      "    \"\"\"\n",
      "    Global Search using vecText, OCR and BarCode with Azure Cognitive Search\n",
      "    \"\"\"\n",
      "    start = time.time()\n",
      "\n",
      "    if not os.path.exists(imagefile):\n",
      "        print(\"[Error] File does not exist:\", imagefile)\n",
      "        return\n",
      "\n",
      "    global results_list\n",
      "\n",
      "    # 1 Images search using sentence transformers\n",
      "    print(\n",
      "        \"\\033[1;31;32m[Step 1. Running images similarity visual search...]\\033[0m\\n\"\n",
      "    )\n",
      "    vectext_list, scores_list = similar_images(\n",
      "        imagefile, centers, model, False,\n",
      "        topn=topn)  # Sentence Transformers only\n",
      "    final_list = vectext_list\n",
      "\n",
      "    # 2 Get OCR text\n",
      "    print(\n",
      "        \"\\n\\033[1;31;32m[Step 2. Extracting any text from the image...]\\033[0m\\n\"\n",
      "    )\n",
      "    # Getting results from Azure Read API\n",
      "    ocr_text = my.get_ocr_text(imagefile)\n",
      "\n",
      "    if ocr_text != '':\n",
      "        print(\"\\033[1;31;34m[Result] Text has been found:\")\n",
      "        print(\"OCR results from the image:\", ocr_text)\n",
      "        print(\"\\033[0m\")\n",
      "        ocr_list = open_text_query(\n",
      "            ocr_text, False,\n",
      "            topn)  # Searching using the Azure Read API results\n",
      "\n",
      "    if ocr_text == '':\n",
      "        print(\"\\033[1;31;91m[Result] No text has been found\\033[0m\")\n",
      "        ocr_list = []\n",
      "\n",
      "    # 3. Get Barcode OCR\n",
      "    print(\n",
      "        \"\\n\\033[1;31;32m[Step 3. Extracting any text any barcode/QRCode of the image...]\\033[0m\\n\"\n",
      "    )\n",
      "    barcode_txt = my.get_barcode_text(\n",
      "        imagefile)  # Get Barcode/QRCode text informations\n",
      "\n",
      "    if barcode_txt != '':\n",
      "        print(\"\\033[1;31;34m[Result] Barcode/QRCode text has been found:\")\n",
      "        print(\"Barcode results from the image:\", barcode_txt)\n",
      "        print(\"\\033[0m\")\n",
      "        barcode_list = open_text_query(\n",
      "            barcode_txt, False,\n",
      "            topn)  # Searching using the Barcode/QRCode results\n",
      "\n",
      "    if barcode_txt == '':\n",
      "        print(\"\\033[1;31;91m[Result] No barcode/QRCode has been found\\033[0m\")\n",
      "        barcode_list = []\n",
      "\n",
      "    results_list = vectext_list + ocr_list + barcode_list\n",
      "\n",
      "    idx = 0\n",
      "    txt_to_remove = ['[', ']']\n",
      "    clean_list = list()\n",
      "\n",
      "    # Need to remove some extra characters\n",
      "    while idx < len(results_list):\n",
      "        results_list[idx] = \"\".join(i for i in results_list[idx]\n",
      "                                    if i not in txt_to_remove)\n",
      "        clean_list.append(results_list[idx])\n",
      "        idx += 1\n",
      "\n",
      "    results_list = list()\n",
      "\n",
      "    for item in clean_list:\n",
      "        if item not in results_list:\n",
      "            results_list.append(item)\n",
      "\n",
      "    del clean_list\n",
      "\n",
      "    print(\"\\nDone in\", round((time.time() - start), 5), \"sec\")\n",
      "\n",
      "    return results_list, vectext_list, ocr_list, barcode_list\n",
      "\n",
      "\n",
      "def global_search_img_list(filelist):\n",
      "    \"\"\"\n",
      "    View all the images from a list of images files\n",
      "    \"\"\"\n",
      "    try:\n",
      "        idx = 0\n",
      "        while idx < len(filelist):\n",
      "            img = mpimg.imread(filelist[idx])\n",
      "            plt.figure()\n",
      "            plt.title(\"Image \" + str(idx + 1) + \" : \" + filelist[idx])\n",
      "            plt.imshow(img)\n",
      "            idx += 1\n",
      "\n",
      "    except:\n",
      "        print(\"[Error]\")\n",
      "\n",
      "\n",
      "def open_text_query(mytext, view=False, maxlimit=10):\n",
      "    \"\"\"\n",
      "    Using text query on the Azure Cognitive Search index\n",
      "    \"\"\"\n",
      "    results = searchClient.search(search_text=mytext)\n",
      "\n",
      "    idx = 1\n",
      "    imageslist = []\n",
      "\n",
      "    print('\\033[1;31;34m')\n",
      "    print(\"Search using query =\", mytext, \"- note: displaying only the first\",\n",
      "          maxlimit, \"results\", \"\\n\")\n",
      "\n",
      "    for result in results:\n",
      "        print('\\033[1;31;34m', idx, \"Image file:\", result['Content'],\n",
      "              '\\033[0m')\n",
      "\n",
      "        if view:\n",
      "            display(Image(filename=result[\"Content\"], height=256, width=256))\n",
      "\n",
      "        print(\"\\033[1;31;34m\")\n",
      "        print(\"OCR:\", \"\\033[1;31;32m\", result['Ocrtext'], \"\\033[1;31;34m\")\n",
      "        print(\"BarCode:\", \"\\033[1;31;32m\", result['Barcodetext'],\n",
      "              \"\\033[1;31;34m\")\n",
      "        print(\"Colors:\", \"\\033[1;31;32m\", result['Colors'], \"\\033[1;31;34m\")\n",
      "        print(\"Tags:\", \"\\033[1;31;32m\", result['Tags'], \"\\033[1;31;34m\")\n",
      "        print(\"Caption:\", \"\\033[1;31;32m\", result['Caption'], \"\\033[0m\", \"\\n\")\n",
      "\n",
      "        if idx <= maxlimit:\n",
      "            imageslist.append(result[\"Content\"])\n",
      "\n",
      "        idx += 1\n",
      "\n",
      "    return imageslist\n",
      "\n",
      "\n",
      "def sentence_transformers_query_search(textquery, centers, model, topn=5):\n",
      "    \"\"\"\n",
      "    Sentence transformers text query using Open AI clip model\n",
      "    \"\"\"\n",
      "    idx = 1\n",
      "    print(\"Finding\", topn, \"images with Open AI text query:\",\n",
      "          str.upper(textquery), \"\\n\")\n",
      "\n",
      "    results = execute_query_search(textquery, centers, model, topn)\n",
      "\n",
      "    for result in results:\n",
      "        print(result)\n",
      "        print(\"\\033[1;31;34m\")\n",
      "        print(idx, \"Image file:\", result[\"Content\"])\n",
      "        print(\"Similarity score =\", result['@search.score'])\n",
      "        display(Image(filename=result[\"Content\"], height=256, width=256))\n",
      "        print()\n",
      "\n",
      "        idx += 1\n",
      "\n",
      "\n",
      "def similar_images(imagefile, centers, model, view, topn):\n",
      "    \"\"\"\n",
      "    Finding similar images using Azure Cognitive Search index\n",
      "    \"\"\"\n",
      "    if not os.path.exists(imagefile):\n",
      "        print(\"Error. File not exist:\", imagefile)\n",
      "        return\n",
      "\n",
      "    images_list = list()\n",
      "    scores_list = list()\n",
      "\n",
      "    results = execute_file_search(imagefile, centers, model, topn)\n",
      "\n",
      "    print(\"Finding\", topn, \"similar images of reference image:\", imagefile,\n",
      "          \"\\n\")\n",
      "    idx = 1\n",
      "\n",
      "    for result in results:\n",
      "        imgfile = result[\"Content\"]\n",
      "        score = result[\"@search.score\"]\n",
      "        print(\"\\033[1;31;34m\", idx, \"Similar image:\", imgfile,\n",
      "              \"Similarity score =\", score, \"\\033[0m\")\n",
      "\n",
      "        if view:\n",
      "            display(Image(filename=imgfile, width=256, height=256))\n",
      "            print(\"\\n\")\n",
      "\n",
      "        images_list.append(imgfile)\n",
      "        scores_list.append(score)\n",
      "\n",
      "        idx += 1\n",
      "\n",
      "    return images_list, scores_list\n",
      "\n",
      "\n",
      "def upload_documents(documents):\n",
      "    \"\"\"\n",
      "    Uploading documents into an Azure cognitive search index\n",
      "    \"\"\"\n",
      "    try:\n",
      "        result = searchClient.upload_documents(documents=documents)\n",
      "        print(\"Upload of new document succeeded: {}\".format(\n",
      "            result[0].succeeded))\n",
      "\n",
      "    except Exception as ex:\n",
      "        print(ex.message)\n",
      "\n",
      "\n",
      "def vec_image_to_text(imagefile, centers, model):\n",
      "    \"\"\"\n",
      "    Doing vec2Text\n",
      "    \"\"\"\n",
      "    curVec = vec2Text.image_embedding(imagefile, model)\n",
      "    vecText = ''\n",
      "\n",
      "    for d in range(len(curVec)):\n",
      "        vecText += vec2Text.convert_field_num_to_string(d) + str(\n",
      "            vec2Text.closest(centers[d], curVec[d])) + ' '\n",
      "    return vecText\n",
      "\n",
      "\n",
      "def vec_query_to_text(query, centers, model):\n",
      "    \"\"\"\n",
      "    Vec query to text\n",
      "    \"\"\"\n",
      "    curVec = vec2Text.text_embedding(query, model)\n",
      "    vecText = ''\n",
      "\n",
      "    for d in range(len(curVec)):\n",
      "        vecText += vec2Text.convert_field_num_to_string(d) + str(\n",
      "            vec2Text.closest(centers[d], curVec[d])) + ' '\n",
      "    return vecText\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my.view_file(\"azureCognitiveSearch.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97607415",
   "metadata": {},
   "source": [
    "## 2. myfunctions.py\n",
    "> This is a custom .py file with some generic python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280e91e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing file: myfunctions.py \n",
      "\n",
      "# Generic python functions\n",
      "# Serge Retkowsky (serge.retkowsky@microsoft.com)\n",
      "# 18-Oct-2022\n",
      "\n",
      "\n",
      "# Multiple imports\n",
      "import configparser\n",
      "import cv2\n",
      "import datetime\n",
      "import glob\n",
      "import humanize\n",
      "import json\n",
      "import logging\n",
      "from math import *\n",
      "import numpy as np\n",
      "import os\n",
      "import pathlib\n",
      "import pendulum\n",
      "import platform\n",
      "import psutil\n",
      "import random\n",
      "import re\n",
      "import requests\n",
      "import shutil\n",
      "import sys\n",
      "import socket\n",
      "import time\n",
      "import uuid\n",
      "\n",
      "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
      "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
      "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
      "from msrest.authentication import CognitiveServicesCredentials\n",
      "from matplotlib import pyplot as plt\n",
      "from pyzbar.pyzbar import decode\n",
      "\n",
      "# Reading config.ini file to retrieve credentials\n",
      "config = configparser.ConfigParser()\n",
      "config_file = 'azureconfig.ini'\n",
      "config.read(config_file)\n",
      "\n",
      "# Azure CV Credentials\n",
      "azure_cv_subscription_key = config.get('AzureComputerVision', 'key')\n",
      "azure_cv_endpoint = config.get('AzureComputerVision', 'endpoint')\n",
      "\n",
      "# Azure CV client\n",
      "computervision_client = ComputerVisionClient(\n",
      "    azure_cv_endpoint, CognitiveServicesCredentials(azure_cv_subscription_key))\n",
      "\n",
      "azure_text_recognition_url = azure_cv_endpoint + \"/vision/v3.2/read/analyze\"\n",
      "headers = {\n",
      "    'Ocp-Apim-Subscription-Key': azure_cv_subscription_key,\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "}\n",
      "\n",
      "# Functions definitions\n",
      "\n",
      "\n",
      "def check_python():\n",
      "    \"\"\"\n",
      "    Check Python version\n",
      "    \"\"\"\n",
      "    try:\n",
      "        print(\"You are using Python:\", sys.version)\n",
      "        print(\"This notebook was made using Python 3.8.5 so this is OK\")\n",
      "\n",
      "        if sys.version[:5] != '3.8.5':\n",
      "            print(\"[Note] This notebook was made using python 3.8.5\")\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display python version\")\n",
      "\n",
      "\n",
      "def create_dir(MYDIR):\n",
      "    \"\"\"\n",
      "    Create a new directory\n",
      "    \"\"\"\n",
      "    if not os.path.exists(MYDIR):\n",
      "        try:\n",
      "            os.mkdir(MYDIR)\n",
      "            print(\"Done. Directory:\", MYDIR, \"has been created\")\n",
      "        except:\n",
      "            print(\"[Error] Cannot create directory\")\n",
      "\n",
      "    else:\n",
      "        print(\"Dir\", MYDIR, \"exist. So you can use it\")\n",
      "\n",
      "\n",
      "def display_multiple_images(mylist,\n",
      "                            nb_cols=3,\n",
      "                            hspace=0.5,\n",
      "                            wspace=0.05,\n",
      "                            axis=False):\n",
      "\n",
      "    plt.figure(figsize=(15, 10))\n",
      "\n",
      "    idx = 1\n",
      "    nb_rows = ceil(len(mylist) / nb_cols)\n",
      "\n",
      "    while idx <= len(mylist):\n",
      "        plt.subplot(nb_rows, nb_cols, idx)\n",
      "        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
      "        img = cv2.cvtColor(cv2.imread(mylist[idx - 1]), cv2.COLOR_BGR2RGB)\n",
      "        plt.imshow(img)\n",
      "\n",
      "        if not axis:\n",
      "            plt.axis(\"off\")\n",
      "\n",
      "        plt.title(\"Image \" + str(idx) + ': ' + mylist[idx - 1], size=10)\n",
      "\n",
      "        idx += 1\n",
      "\n",
      "\n",
      "def display_random_images(mydir,\n",
      "                          nb_images=10,\n",
      "                          nb_cols=4,\n",
      "                          hspace=0.5,\n",
      "                          wspace=0.05,\n",
      "                          titlesize=12):\n",
      "    \"\"\"\n",
      "    Display random images from a directory\n",
      "    \"\"\"\n",
      "    files_list = [\n",
      "        file for file in os.listdir(mydir)\n",
      "        if file.endswith(('jpeg', 'png', 'jpg', 'JPG', 'JPEG', 'PNG'))\n",
      "    ]\n",
      "\n",
      "    plt.figure(figsize=(15, 30))\n",
      "\n",
      "    if nb_cols < 2:\n",
      "        nb_cols = 2\n",
      "\n",
      "    print(\"Some\", nb_images, \"random images from the\", len(files_list),\n",
      "          \"images:\")\n",
      "    nb_rows = nb_images - nb_cols\n",
      "\n",
      "    for idx in range(1, nb_images + 1):\n",
      "        plt.subplot(nb_rows, nb_cols, idx)\n",
      "        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
      "        random_idx = int(random.random() * len(files_list))\n",
      "        img = cv2.cvtColor(cv2.imread(mydir + \"/\" + files_list[random_idx]),\n",
      "                           cv2.COLOR_BGR2RGB)\n",
      "        plt.axis('off')\n",
      "        plt.imshow(img)\n",
      "        plt.title(mydir + \"/\" + files_list[random_idx], size=titlesize)\n",
      "\n",
      "\n",
      "def get_barcode_text(IMAGEFILE):\n",
      "    \"\"\"\n",
      "    Get Barcode informations from a file using pyzbar. \n",
      "    Works with barcodes or QR Codes\n",
      "    \"\"\"\n",
      "    try:\n",
      "        if not os.path.exists(IMAGEFILE):\n",
      "            print(\"Error. File not exist:\", IMAGEFILE)\n",
      "            return\n",
      "\n",
      "        decodingbarcode = decode(cv2.imread(IMAGEFILE))\n",
      "        barcode_txt = ''\n",
      "\n",
      "        if decodingbarcode == []:\n",
      "            barcode_txt = ''\n",
      "\n",
      "        else:\n",
      "            barcode_txt = decodingbarcode[0][0].decode('utf-8')\n",
      "\n",
      "        return barcode_txt\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot get barcode information using pyzbar\")\n",
      "\n",
      "\n",
      "def get_image_azure_cvresults(IMAGEFILE):\n",
      "    \"\"\"ImageAnalysisInStream.\n",
      "    This will analyze an image from a stream and return main colors, \n",
      "    tags and caption using Azure CV\n",
      "    \"\"\"\n",
      "    if not os.path.exists(IMAGEFILE):\n",
      "        print(\"Error. File not exist:\", IMAGEFILE)\n",
      "        return\n",
      "\n",
      "    img_tags_list = []\n",
      "    img_colors_list = []\n",
      "    idx1 = 0\n",
      "    idx2 = 0\n",
      "    idx3 = 0\n",
      "\n",
      "    img_tags = \"\"\n",
      "    img_colors = \"\"\n",
      "\n",
      "    time.sleep(1)\n",
      "\n",
      "    with open(IMAGEFILE, \"rb\") as image_stream:\n",
      "        image_analysis = computervision_client.analyze_image_in_stream(\n",
      "            image=image_stream,\n",
      "            visual_features=[\n",
      "                VisualFeatureTypes.color,\n",
      "                VisualFeatureTypes.tags,\n",
      "                VisualFeatureTypes.description,\n",
      "            ])\n",
      "\n",
      "    img_dominant_color = image_analysis.color.dominant_colors\n",
      "    img_dominant_color_foreground = image_analysis.color.dominant_color_foreground\n",
      "    img_dominant_color_background = image_analysis.color.dominant_color_background\n",
      "\n",
      "    while idx1 < len(img_dominant_color):\n",
      "        img_colors_list.append(img_dominant_color[idx1])\n",
      "        idx1 += 1\n",
      "\n",
      "    img_colors_list.append(img_dominant_color_foreground)\n",
      "    img_colors_list.append(img_dominant_color_background)\n",
      "    img_colors_list = [*set(img_colors_list)]  # Deduplication\n",
      "\n",
      "    while idx2 < len(img_colors_list):\n",
      "        img_colors = img_colors + img_colors_list[idx2] + ' '\n",
      "        idx2 += 1\n",
      "    img_colors = img_colors[:-1]\n",
      "\n",
      "    for tag in image_analysis.tags:\n",
      "        if tag.confidence >= 0.5:  # Only main confidence tags\n",
      "            img_tags_list.append(tag.name)\n",
      "\n",
      "    while idx3 < len(img_tags_list):\n",
      "        img_tags = img_tags + img_tags_list[idx3] + ' '\n",
      "        idx3 += 1\n",
      "    img_tags = img_tags[:-1]\n",
      "\n",
      "    img_caption = image_analysis.description.captions[0].text  # get caption\n",
      "\n",
      "    return img_colors, img_tags, img_caption\n",
      "\n",
      "\n",
      "def get_ocr_text(IMAGEFILE):\n",
      "    \"\"\"\n",
      "    Extract text from an image using Azure Read API\n",
      "    \"\"\"\n",
      "    if not os.path.exists(IMAGEFILE):\n",
      "        print(\"Error. File not exist:\", IMAGEFILE)\n",
      "        return\n",
      "\n",
      "    params = {}\n",
      "\n",
      "    fullocr = []\n",
      "    nb_txt = 0\n",
      "    ocr_text = ''\n",
      "    poll = True\n",
      "\n",
      "    dataimg = open(IMAGEFILE, \"rb\").read()  # Reading image\n",
      "\n",
      "    response = requests.post(azure_text_recognition_url,\n",
      "                             headers=headers,\n",
      "                             params=params,\n",
      "                             data=dataimg)\n",
      "\n",
      "    response.raise_for_status()\n",
      "    \"\"\"\n",
      "    The call returns with a response header field called Operation-Location. \n",
      "    The Operation-Location value is a URL that contains the Operation ID to \n",
      "    be used in the next step.\n",
      "    operation_url = response.headers[\"Operation-Location\"]\n",
      "    \"\"\"\n",
      "    analysis = {}\n",
      "    \"\"\"\n",
      "    The second step is to call Get Read Results operation.\n",
      "    This operation takes as input the operation ID that was created \n",
      "    by the Read operation.\n",
      "    \"\"\"\n",
      "    while (poll):\n",
      "        response_final = requests.get(response.headers[\"Operation-Location\"],\n",
      "                                      headers=headers)\n",
      "        analysis = response_final.json()\n",
      "        # This is to avoid exceeding the requests per second (RPS) rate.\n",
      "        time.sleep(2)\n",
      "\n",
      "        if (\"analyzeResult\" in analysis):\n",
      "            poll = False\n",
      "        if (\"status\" in analysis and analysis['status'] == 'failed'):\n",
      "            poll = False\n",
      "\n",
      "    if (\"analyzeResult\" in analysis):\n",
      "        full_ocr = [\n",
      "            (line[\"boundingBox\"], line[\"text\"])\n",
      "            for line in analysis[\"analyzeResult\"][\"readResults\"][0][\"lines\"]\n",
      "        ]\n",
      "\n",
      "    while nb_txt < len(full_ocr):\n",
      "        ocr_text = ocr_text + full_ocr[nb_txt][\n",
      "            1] + ' '  # concatenation of all detected strings\n",
      "        nb_txt += 1\n",
      "\n",
      "    ocr_text = ocr_text.rstrip()  # removing the last space\n",
      "\n",
      "    return ocr_text\n",
      "\n",
      "\n",
      "def get_storage_infos(plot=True):\n",
      "    \"\"\"\n",
      "    Get storage informations\n",
      "    \"\"\"\n",
      "    print(\"Storage:\\n\")\n",
      "    total, used, free = shutil.disk_usage(\"/\")\n",
      "    used_pct = round(used / total * 100, 2)\n",
      "    free_pct = round(free / total * 100, 2)\n",
      "    print(\"Total:\", humanize.naturalsize(total))\n",
      "    print(\"- Used:\", humanize.naturalsize(used), \"|\", used_pct, \"%\")\n",
      "    print(\"- Free:\", humanize.naturalsize(free), \"|\", free_pct, \"%\")\n",
      "\n",
      "    if plot:\n",
      "        labels = [\n",
      "            \"Used: \" + str(humanize.naturalsize(used)),\n",
      "            \"Free: \" + str(humanize.naturalsize(free))\n",
      "        ]\n",
      "        values = [used, free]\n",
      "        fig = plt.figure(figsize=(3, 3))\n",
      "        plt.pie(values, labels=labels)\n",
      "        plt.title(\"Storage\")\n",
      "        plt.show()\n",
      "\n",
      "    return total, used, free\n",
      "\n",
      "\n",
      "def get_system_info():\n",
      "    \"\"\"\n",
      "    Get system informations\n",
      "    \"\"\"\n",
      "    try:\n",
      "        info = {}\n",
      "        info['Platform'] = platform.system()\n",
      "        info['Platform-release'] = platform.release()\n",
      "        info['Platform-version'] = platform.version()\n",
      "        info['Architecture'] = platform.machine()\n",
      "        info['Hostname'] = socket.gethostname()\n",
      "        info['IP-address'] = socket.gethostbyname(socket.gethostname())\n",
      "        info['MAC-address'] = ':'.join(\n",
      "            re.findall('..', '%012x' % uuid.getnode()))\n",
      "        info['Processor'] = platform.processor()\n",
      "        info['Python version'] = sys.version\n",
      "        info['RAM'] = str(round(psutil.virtual_memory().total /\n",
      "                                (1024.0**3))) + \" Gb\"\n",
      "\n",
      "        print(\"System Informations:\\n\")\n",
      "        print(json.dumps(info, indent=2, sort_keys=True))\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display system informations\")\n",
      "\n",
      "\n",
      "def get_today():\n",
      "    \"\"\"\n",
      "    Display date and time\n",
      "    \"\"\"\n",
      "    try:\n",
      "        current_dt = datetime.datetime.utcnow()\n",
      "        current_date = f\"{current_dt:%d-%m-%Y %H:%M:%S}\"\n",
      "        return current_date\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display datetime\")\n",
      "\n",
      "\n",
      "def get_time(ms=False):\n",
      "    \"\"\"\n",
      "    Display time\n",
      "    \"\"\"\n",
      "    try:\n",
      "        current_dt = datetime.datetime.utcnow()\n",
      "\n",
      "        if not ms:\n",
      "            current_time = f\"{current_dt:%H:%M:%S}\"\n",
      "\n",
      "        else:\n",
      "            current_time = f\"{current_dt:%H:%M:%S.%f}\"\n",
      "\n",
      "        return current_time\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display time\")\n",
      "\n",
      "\n",
      "def image_view(IMAGEFILE, w=15, h=10, axis=True):\n",
      "    \"\"\"\n",
      "    Function to display an image using a filename\n",
      "    \"\"\"\n",
      "    try:\n",
      "        img = cv2.imread(IMAGEFILE)\n",
      "        file_height, file_width, file_c = img.shape\n",
      "        imgtitle = IMAGEFILE + \" ( width = \" + str(\n",
      "            file_width) + \" height = \" + str(file_height) + \" )\"\n",
      "        plt.figure(figsize=(w, h))\n",
      "\n",
      "        if axis:\n",
      "            plt.axis('on')\n",
      "\n",
      "        else:\n",
      "            plt.axis('off')\n",
      "\n",
      "        plt.title(imgtitle)\n",
      "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display image using opencv from a filename\")\n",
      "\n",
      "\n",
      "def image_view_index(MYDIR, IDX):\n",
      "    \"\"\"\n",
      "    Python function to display image with additional \n",
      "    information like shape, date and size\n",
      "    Argument is an index from a list of files\n",
      "    \"\"\"\n",
      "    try:\n",
      "        images = glob.glob(MYDIR + '/*.*')\n",
      "        fullpath_image = [image.replace('\\\\', '/') for image in images]\n",
      "        filename_image = [image.split('/')[-1] for image in images]\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Error during the creation of the files list\")\n",
      "\n",
      "    try:\n",
      "        img = cv2.imread(fullpath_image[IDX])\n",
      "        file_height, file_width, file_c = img.shape\n",
      "        file_size = os.path.getsize(fullpath_image[IDX])\n",
      "        file_date = datetime.datetime.fromtimestamp(\n",
      "            pathlib.Path(fullpath_image[IDX]).stat().st_mtime)\n",
      "        print(\"Image file:\", fullpath_image[IDX], '\\nWidth =', file_width,\n",
      "              'Height =', file_height, \"\\nSize:\",\n",
      "              humanize.naturalsize(file_size), \"Date:\", file_date)\n",
      "        plt.figure(figsize=(6, 6))\n",
      "        plt.axis('off')\n",
      "        plt.title(filename_image[IDX])\n",
      "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display image\")\n",
      "\n",
      "\n",
      "def list_dir(MYDIR):\n",
      "    \"\"\"\n",
      "    list all files with informations\n",
      "    \"\"\"\n",
      "    idx = 1\n",
      "    print(\"Files in directory:\", MYDIR, \"\\n\")\n",
      "\n",
      "    try:\n",
      "        for file in os.scandir(MYDIR):\n",
      "            print(idx, \"\\t\",\n",
      "                  datetime.datetime.fromtimestamp(file.stat().st_atime),\n",
      "                  humanize.naturalsize(file.stat().st_size), \"\\t\", file.name)\n",
      "            idx += 1\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Check if directory exist\")\n",
      "\n",
      "\n",
      "def now():\n",
      "    \"\"\"\n",
      "    Get current date\n",
      "    \"\"\"\n",
      "    try:\n",
      "        now = pendulum.now('Europe/Paris')\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Cannot display datetime using pendulum python module\")\n",
      "\n",
      "    return now\n",
      "\n",
      "\n",
      "def number_files(MYDIR):\n",
      "    \"\"\"\n",
      "    Function to count the number of files from a directory\n",
      "    \"\"\"\n",
      "    try:\n",
      "        for root, _, files in os.walk(MYDIR):\n",
      "            print(root, \"=\", humanize.intcomma(len(files)))\n",
      "            print(\"\\nThe directory\", root, \"contains\",\n",
      "                  humanize.intword(len(files)), \"files\")\n",
      "\n",
      "    except:\n",
      "        print(\"[Error] Check if directory exist\")\n",
      "\n",
      "\n",
      "def similar_images_display(imageref_file,\n",
      "                           files_list,\n",
      "                           scores_list,\n",
      "                           w=15,\n",
      "                           h=10,\n",
      "                           nb_cols=3,\n",
      "                           hspace=0.5,\n",
      "                           wspace=0.05,\n",
      "                           axis=False,\n",
      "                           textsize=10):\n",
      "    \"\"\"\n",
      "    Display reference image and similar images from a list\n",
      "    \"\"\"\n",
      "    imageref_list = list()\n",
      "    imageref_list.append(imageref_file)\n",
      "    images_list = imageref_list + files_list\n",
      "\n",
      "    plt.figure(figsize=(w, h))\n",
      "\n",
      "    idx = 0\n",
      "    nb_rows = ceil(len(images_list) / nb_cols)\n",
      "\n",
      "    while idx < len(images_list):\n",
      "        plt.subplot(nb_rows, nb_cols, idx + 1)\n",
      "        plt.subplots_adjust(hspace=hspace, wspace=wspace)\n",
      "        img = cv2.imread(images_list[idx])\n",
      "\n",
      "        if not axis:\n",
      "            plt.axis(\"off\")\n",
      "\n",
      "        if idx == 0:\n",
      "            plt.title(\"Reference image\\n\" + images_list[0], size=textsize)\n",
      "\n",
      "        if idx > 0:\n",
      "            score = str(round(scores_list[idx - 1], 2))\n",
      "            img_h, img_w, img_c = img.shape\n",
      "            img_size = humanize.naturalsize(os.path.getsize(images_list[idx]))\n",
      "            img_date = datetime.datetime.fromtimestamp(\n",
      "                pathlib.Path(images_list[idx]).stat().st_mtime)\n",
      "\n",
      "            plt.title(\"Similar image \" + str(idx) + \" | score =\" + score +\n",
      "                      \"\\n\" + images_list[idx] + '\\nh: ' + str(img_h) + ' w: ' +\n",
      "                      str(img_w) + ' | ' + str(img_date) + ' | ' +\n",
      "                      str(img_size),\n",
      "                      size=textsize)\n",
      "\n",
      "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "        plt.imshow(img_rgb)\n",
      "\n",
      "        idx += 1\n",
      "\n",
      "\n",
      "def view_file(FILENAME):\n",
      "    \"\"\"\n",
      "    View file content\n",
      "    \"\"\"\n",
      "    print(\"Viewing file:\", FILENAME, \"\\n\")\n",
      "    with open(FILENAME, 'r') as f:\n",
      "        print(f.read())\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my.view_file(\"myfunctions.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81738b0",
   "metadata": {},
   "source": [
    "## 3. Azure CV credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55c5972",
   "metadata": {},
   "source": [
    "You need to update the azureconfig.ini file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84da7e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 413 Oct 18 12:36 azureconfig.ini\r\n"
     ]
    }
   ],
   "source": [
    "!ls azureconfig.ini -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b918d62",
   "metadata": {},
   "source": [
    "## 4. Python librairies installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84638a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebe1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c06d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install pyzbar:\n",
    "#!sudo apt-get install libzbar0 --yes\n",
    "#!pip install pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d549af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda create -n py37-vector-search python=3.7 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba75709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge jupyterlab\n",
    "#!conda install pytorch torchvision torchaudio cpuonly -c pytorch --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7b4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c anaconda gensim --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4be867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install smart_open==2.0.0 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e055c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac41a604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1d9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e30ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
